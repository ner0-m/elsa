stages:
- docker-build
- static-test
- compile
- test
- sanitizer
- coverage
- docs

### workflow ###

# Conditions in plain english:
# - the pipeline
# - Create a pipeline if, the pipeline is a merge request pipeline, or
# - Do not create a pipeline, if a branch pipeline is triggered, but an open merge request exists for that branch, or
# - Create a pipeline if a branch pipeline is triggered, without an associated open merge requests
# based on: https://docs.gitlab.com/ee/ci/yaml/workflow.html#switch-between-branch-pipelines-and-merge-request-pipelines
workflow:
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"
      when: never
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_COMMIT_BRANCH

### workflow ###

# Conditions in plain english:
# - the pipeline
# - Create a pipeline if, the pipeline is a merge request pipeline, or
# - Do not create a pipeline, if a branch pipeline is triggered, but an open merge request exists for that branch, or
# - Create a pipeline if a branch pipeline is triggered, without an associated open merge requests
# based on: https://docs.gitlab.com/ee/ci/yaml/workflow.html#switch-between-branch-pipelines-and-merge-request-pipelines
workflow:
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"
      when: never
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_COMMIT_BRANCH

### Cache setup ###

# Caches should only be used for caching between pipelines not jobs
# By default, have a unique and separate cache for each branch and job in the CI, otherwise it can happen that
# different build configurations are spilled into different jobs and sporadic build failure occurs.
cache:
  key: "$CI_COMMIT_REF_SLUG-$CI_JOB_STAGE-$CI_JOB_NAME"
  paths:
    - build/_deps/*

### job templates ###

#### Schedule jobs ####

# run job if connected to a schedule, merge request or some other things
.job_template: &run_on_merge_requests
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule"'
    - when: never

#### Build job templates ####

.job_template: &build_job_artifact
  stage: compile
  artifacts:
    name: "$CI_JOB_NAME-$CI_COMMIT_REF_NAME"
    paths:
      # The actual build artifacts
      - build/bin
      - build/lib
      - build/pyelsa/
      - build/elsa/elsaConfig.cmake
      - build/elsa/elsaConfigVersion.cmake

      # If we ever generate headers, store them as well
      - build/elsa/**/*.h

      # CTest files
      - build/**/CTestTestfile.cmake
      - build/**/tests/test_*include-*.cmake
      - build/**/tests/test_*tests-*.cmake
      - build/Testing
      - build/junit_report.xml

      # Add elsa install to artifact
      - install-elsa/include/elsa/**/*.h
      - install-elsa/include/elsa/**/*.hpp
      - install-elsa/include/elsa/**/*.cuh
      - install-elsa/lib/cmake/elsa/**/*.cmake
      - install-elsa/lib/libelsa*.a
      # Add doctest install to artifact
      - install-elsa/include/doctest/**/*.h
      - install-elsa/lib/cmake/doctest/**/*.cmake
      # Add spdlog install to artifact
      - install-elsa/include/spdlog/**/*.h
      - install-elsa/lib/cmake/spdlog/**/*.cmake
      - install-elsa/lib/libspdlog.a
      - install-elsa/lib/pkgconfig/spdlog.pc
    exclude:
      - build/_deps/*
    expire_in: 60 mins

.buildjob_script_normal:
  script: &buildjob_normal
    - mkdir -p build
    - cd build
    - if [ $COMPILER == "clang" ]; then CMAKE_EXTRA_ARGS="-DCMAKE_CXX_FLAGS=\"-stdlib=libc++\" -DCMAKE_EXE_LINKER_FLAGS=\"-lc++abi\""; fi;
    - if [ $COMPILER == "nvcc" ]; then CMAKE_EXTRA_ARGS="-DELSA_CUDA_VECTOR=ON -DELSA_BENCHMARKS=ON"; fi;
    - echo $CMAKE_EXTRA_ARGS
    - cmake .. -GNinja -DELSA_BENCHMARKS=ON -DCMAKE_INSTALL_PREFIX="../install-elsa" $CMAKE_EXTRA_ARGS
    - ninja
    - ninja build-tests
    - ninja build-benchmarks
    - ninja build-examples
    - ninja install

#### Test job templates ####

.testjob_template: &test_job_artifact
  script:
    - cd build
    - ctest --schedule-random --output-junit junit_report.xml || ctest --rerun-failed --output-on-failure
  artifacts:
    name: "$CI_COMMIT_REF_SLUG-$CI_JOB_NAME"
    paths:
      - build/
    expire_in: 60 mins
    reports:
      junit: "build/junit_report.xml"

#### Install job templates ####

.installjob_anchors: &install_job
  <<: *run_on_merge_requests
  script:
    - git clone https://gitlab.lrz.de/IP/elsa_testing.git /tmp/elsa_testing
    - cd /tmp/elsa_testing
    - mkdir -p build/ && cd build/
    - echo $CMAKE_EXTRA_ARGS
    - cmake .. -GNinja -DELSA_INSTALL_DIR="$CI_PROJECT_DIR/install-elsa" $CMAKE_EXTRA_ARGS
    - ninja

### static test ###

clang-format:
  stage: static-test
  image: $CI_REGISTRY/ip/elsa/clang:14
  script:
    ./tools/ci_scripts/clang-format-test.sh
  tags:
    - linux
    - elsa
    - clang

clang-tidy:
  stage: static-test
  image: $CI_REGISTRY/ip/elsa/cuda:11.7.0
  script:
    ./tools/ci_scripts/clang-tidy.sh
  tags:
    - linux
    - elsa
    - clang

comment-formating:
  stage: static-test
  image: $CI_REGISTRY/ip/elsa/clang:14
  script:
    ./tools/ci_scripts/check-comment-style.sh
  allow_failure: true
  tags:
    - linux
    - elsa
    - clang

.cmake-format:
  stage: static-test
  image: $CI_REGISTRY/ip/elsa/clang:14
  script:
    ./tools/ci_scripts/cmake-format-test.sh
  tags:
    - linux
    - elsa
    - clang

cmake-lint:
  stage: static-test
  image: $CI_REGISTRY/ip/elsa/clang:14
  script:
    ./tools/ci_scripts/cmake-lint-test.sh
  tags:
    - linux
    - elsa
    - clang

### compile jobs ###

build:
  <<: *build_job_artifact
  image: $CI_REGISTRY/ip/elsa/pybind:$COMPILER-$COMPILER_VERSION
  script:
  - *buildjob_normal
  parallel:
    matrix:
      - COMPILER_VERSION: [10, 11, 12, 13]
        COMPILER: clang
      - COMPILER_VERSION: [11, 12]
        COMPILER: gcc
  tags:
    - linux
    - elsa
    - $COMPILER

build-cuda:
  <<: *build_job_artifact
  image: $CI_REGISTRY/ip/elsa/cuda:$CUDA_VERSION
  script:
    - *buildjob_normal
  parallel:
    matrix:
      - CUDA_VERSION: [11.7.0, 11.6.2, 11.5.2]
        COMPILER: nvcc
  tags:
    - linux
    - elsa
    - gcc
    - cuda

### test jobs ###

.test-compiler:
  <<: *test_job_artifact
  stage: test
  image: $CI_REGISTRY/ip/elsa/pybind:$COMPILER-$COMPILER_VERSION
  tags:
    - linux
    - elsa
    - $COMPILER

.test-gcc:
  extends: .test-compiler
  variables:
    COMPILER: gcc

.test-clang:
  extends: .test-compiler
  variables:
    COMPILER: clang

.test-cuda:
  <<: *test_job_artifact
  stage: test
  image: $CI_REGISTRY/ip/elsa/cuda:$CUDA_VERSION
  tags:
    - linux
    - elsa
    - gcc
    - cuda

# At the time of writing, variables from the parallel:matrix can not be used in the dependency list
# see https://gitlab.com/gitlab-org/gitlab/-/merge_requests/82734 and
# https://forum.gitlab.com/t/ci-specifying-artifact-dependencies-when-using-parallel-matrix/45026/2
# TODO: Once this is implemented use it!
test-gcc12:
  extends: .test-gcc
  dependencies:
    - "build: [12, gcc]"
  variables:
    COMPILER_VERSION: 12

test-clang10:
  extends: .test-clang
  dependencies:
    - "build: [10, clang]"
  variables:
    COMPILER_VERSION: 10

test-clang11:
  extends: .test-clang
  dependencies:
    - "build: [11, clang]"
  variables:
    COMPILER_VERSION: 11

test-clang12:
  extends: .test-clang
  dependencies:
    - "build: [12, clang]"
  variables:
    COMPILER_VERSION: 12

test-clang13:
  extends: .test-clang
  dependencies:
    - "build: [13, clang]"
  variables:
    COMPILER_VERSION: 13

test-cuda-11.7:
  extends: .test-cuda
  dependencies:
    - "build-cuda: [11.7.0, nvcc]"
  variables:
    CUDA_VERSION: 11.7.0

test-cuda-11.6:
  extends: .test-cuda
  dependencies:
    - "build-cuda: [11.6.2, nvcc]"
  variables:
    CUDA_VERSION: 11.6.2

test-cuda-11.5:
  extends: .test-cuda
  dependencies:
    - "build-cuda: [11.5.2, nvcc]"
  variables:
    CUDA_VERSION: 11.5.2

### Install jobs ###

.install-compiler:
  <<: *install_job
  stage: test
  image: $CI_REGISTRY/ip/elsa/pybind:$COMPILER-$COMPILER_VERSION
  tags:
    - linux
    - elsa
    - $COMPILER

.install-gcc:
  extends: .install-compiler
  variables:
    COMPILER: gcc

.install-clang:
  extends: .install-compiler
  variables:
    COMPILER: clang
    CMAKE_EXTRA_ARGS: "-DCMAKE_CXX_FLAGS=\"-stdlib=libc++\" -DCMAKE_EXE_LINKER_FLAGS=\"-lc++abi\""

.install-cuda:
  <<: *install_job
  stage: test
  image: $CI_REGISTRY/ip/elsa/cuda:$CUDA_VERSION
  script:
    - git clone https://gitlab.lrz.de/IP/elsa_testing.git /tmp/elsa_testing
    - cd /tmp/elsa_testing
    - mkdir -p build/ && cd build/
    - cmake .. -GNinja -DELSA_INSTALL_DIR="$CI_PROJECT_DIR/install-elsa" -DELSA_CUDA_VECTOR=ON
    - ninja
  tags:
    - linux
    - elsa
    - gcc
    - cuda

install-gcc12:
  extends: .install-gcc
  dependencies:
    - "build: [12, gcc]"
  variables:
    COMPILER_VERSION: 12

install-clang10:
  extends: .install-clang
  dependencies:
    - "build: [10, clang]"
  variables:
    COMPILER_VERSION: 10

install-clang11:
  extends: .install-clang
  dependencies:
    - "build: [11, clang]"
  variables:
    COMPILER_VERSION: 11

install-clang12:
  extends: .install-clang
  dependencies:
    - "build: [12, clang]"
  variables:
    COMPILER_VERSION: 12

install-clang13:
  extends: .install-clang
  dependencies:
    - "build: [13, clang]"
  variables:
    COMPILER_VERSION: 13

install-cuda-11.5:
  extends: .install-cuda
  dependencies:
    - "build-cuda: [11.5.2, nvcc]"
  variables:
    CUDA_VERSION: 11.5.2

install-cuda-11.6:
  extends: .install-cuda
  dependencies:
    - "build-cuda: [11.6.2, nvcc]"
  variables:
    CUDA_VERSION: 11.6.2

install-cuda-11.7:
  extends: .install-cuda
  dependencies:
    - "build-cuda: [11.7.0, nvcc]"
  variables:
    CUDA_VERSION: 11.7.0

### sanitizers ###

.cuda-memcheck:
  <<: *run_on_merge_requests
  stage: sanitizer
  image: $CI_REGISTRY/ip/elsa/cuda:$CUDA_VERSION
  script:
    - ./tools/ci_scripts/cuda-memcheck.sh
  tags:
    - linux
    - elsa
    - gcc
    - cuda

cuda-memcheck-11.7:
  extends: .cuda-memcheck
  dependencies:
    - test-cuda-11.7
  variables:
    CUDA_VERSION: 11.7.0

cuda-memcheck-11.6:
  extends: .cuda-memcheck
  dependencies:
    - test-cuda-11.6
  variables:
    CUDA_VERSION: 11.6.2

cuda-memcheck-11.5:
  extends: .cuda-memcheck
  dependencies:
    - test-cuda-11.5
  variables:
    CUDA_VERSION: 11.5.2

# Be sure to run this job with container which has privaledge mode set
asan-ubsan:
  <<: *run_on_merge_requests
  stage: sanitizer
  image: $CI_REGISTRY/ip/elsa/cuda:11.7.0
  dependencies: []
  script:
    - mkdir -p build
    - cd build
    - cmake -GNinja -DELSA_BUILD_CUDA_PROJECTORS=OFF -DELSA_BUILD_PYTHON_BINDINGS=OFF -DCMAKE_BUILD_TYPE=Debug -DELSA_SANITIZER="Address;Undefined" ..
    - ninja tests
  tags:
    - linux
    - elsa
    - gcc
    - cuda


### test coverage ###

# Enforce GCC for test coverage, as our coverage only works with gcov and acts weird with clang
test-coverage:
  <<: *run_on_merge_requests
  stage: coverage
  image: $CI_REGISTRY/ip/elsa/cuda:11.7.0
  dependencies: []
  coverage: '/^\s+lines.+:.\d+(\.\d+)?%.*\(.*\)$/'
  script:
    - mkdir -p build
    - cd build
    - CXX=g++ cmake .. -GNinja -DELSA_BUILD_PYTHON_BINDINGS=OFF -DCMAKE_BUILD_TYPE=Debug -DELSA_COVERAGE=ON
    - ninja tests
    - ninja test_coverage
  artifacts:
    name: "$CI_JOB_NAME-$CI_COMMIT_REF_NAME-coverage"
    paths:
      - build/test_coverage/
    expire_in: 60 mins
  tags:
    - linux
    - elsa
    - gcc
    - cuda


### deploy docs and coverage report ###

deploy-docs:
  rules:
    - if: '$CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule"'
  stage: docs
  dependencies:
    - test-coverage
  script:
    - mkdir -p build
    - cd build
    - cmake .. -GNinja
    - ninja docs
    - cp -r docs/sphinx/* /var/www/ciip/elsadocs/
    - cd ..
    - cp -r build/test_coverage/* /var/www/ciip/elsacoverage/
  tags:
    - elsa-docs-deploy


### Docker jobs ###

.build-docker-base:
  stage: docker-build
  rules:
    - changes:
      - tools/docker/**/*
  allow_failure: true
  retry: 2
  before_script:
    - docker info
    - docker login -u $CI_DEPLOY_USER -p $CI_DEPLOY_PASSWORD $CI_REGISTRY
  after_script:
    - docker logout $CI_REGISTRY
  tags:
    - docker

.build-docker-base-compiler:
  extends: .build-docker-base
  script:
    - cd tools/docker
    - echo "Building image for $COMPILER version $COMPILER_VERSION"
    - image=elsa/$COMPILER:$COMPILER_VERSION
    - pybind=elsa/pybind:$COMPILER-$COMPILER_VERSION
    - docker build --pull -f ${DOCKER_FILE} -t $CI_REGISTRY/ip/$image --build-arg="VERSION=$COMPILER_VERSION" .
    - docker build --pull -f DocFilePyBinds -t $CI_REGISTRY/ip/$pybind --build-arg IMAGE="$CI_REGISTRY/ip/$image" --build-arg LLVM_PKG_VERSION="$LLVM_VERSION" .
    - echo $image
    - echo $pybind
    - docker push $CI_REGISTRY/ip/$image
    - docker push $CI_REGISTRY/ip/$pybind


build-docker-compiler:
  extends: .build-docker-base-compiler
  variables:
    LLVM_VERSION: 11 # Debian currently has no other version available
  parallel:
    matrix:
      - COMPILER: "clang"
        COMPILER_VERSION: [10, 11, 12, 13, 14]
        DOCKER_FILE: DocFileClangBase
      - COMPILER: "gcc"
        COMPILER_VERSION: [9, 10, 11, 12]
        DOCKER_FILE: DocFileGccBase

build-docker-cuda:
  extends: .build-docker-base
  script:
    - cd tools/docker
    - echo "Building image for cuda version $CUDA_VERSION"
    - docker build --pull -f DocFileCudaBase -t $CI_REGISTRY/ip/elsa/cuda:${CUDA_VERSION}
        --build-arg="GCC_VERSION=$GCC_VERSION"
        --build-arg="CLANG_VERSION=$CLANG_VERSION"
        --build-arg="VERSION=$CUDA_VERSION" .
    - docker push $CI_REGISTRY/ip/elsa/cuda:${CUDA_VERSION}
  parallel:
    matrix:
      - CUDA_VERSION: [11.7.0, 11.6.2, 11.5.2]
        GCC_VERSION: 11
        CLANG_VERSION: 12
      - CUDA_VERSION: [11.4.3, 11.3.1, 11.2.2, 11.1.1, 11.0.3]
        GCC_VERSION: 10
        CLANG_VERSION: 10
